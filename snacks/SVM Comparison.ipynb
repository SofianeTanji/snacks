{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SVM Comparison\n",
                "This notebook runs a comparison between ThunderSVM, LibSVM, Pegasos, ~~liquidSVM~~ and Snacks on 3 binary classification datasets:\n",
                " - a9a\n",
                " - SUSY\n",
                " - HIGGS",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The autoreload extension is already loaded. To reload it, use:\n",
                        "  %reload_ext autoreload\n",
                    ],
                }
            ],
            "source": ["%load_ext autoreload\n", "%autoreload 2"],
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "import utils\n",
                "import time\n",
                "import os\n",
                "import sys\n",
                "\n",
                'os.environ["CUDA_VISIBLE_DEVICES"] = "0"\n',
                'sys.path.append("../")',
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import all SVM solvers, data embedding functions and time method\n",
                "from svm import Snacks\n",
                "from pegasos import PegasosSVMClassifier\n",
                "from sklearn import svm",
            ],
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": ["#### Utility functions for benchmarking"],
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "def prepare_data(data, num_centers, gamma, full):\n",
                '    if data == "a9a":\n',
                '        Xtr, Xts, Ytr, Yts = utils.dataloader("../datasets/a9a", 0.7)\n',
                '    elif data == "SUSY":\n',
                '        Xtr, Xts, Ytr, Yts = utils.dataloader("../datasets/SUSY", 0.7)\n',
                '    elif data == "HIGGS":\n',
                '        Xtr, Xts, Ytr, Yts = utils.dataloader("../datasets/HIGGS", 0.7)\n',
                "    else:\n",
                "        print(\n",
                '            f"You asked for dataset {data} while Snacks only support a9a, SUSY and HIGGS"\n',
                "        )\n",
                "\n",
                "    Xtr, Ytr, Xts, Yts = utils.kernel_embedding(\n",
                "        Xtr, Ytr, Xts, Yts, num_centers, gamma=gamma\n",
                "    )\n",
                "\n",
                "    return Xtr, Ytr, Xts, Yts",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_snacks(Xtr, Ytr, Xts, Yts, nb_iterations, lambda_reg, stepsize):\n",
                '    print("Snacks\' performance : ")\n',
                "    model = Snacks(\n",
                "        nb_iterations=nb_iterations, lambda_reg=lambda_reg, stepsize=stepsize\n",
                "    )\n",
                "    ts = time.perf_counter()\n",
                "    model.fit(Xtr, Ytr)\n",
                "    te = time.perf_counter()\n",
                "    score = model.score(Xts, Yts)\n",
                '    print(f"in {(te - ts):.2f}s, C-err is {100 - score * 100:.2f}%")\n',
                "    tr_score = model.score(Xtr, Ytr)\n",
                '    print(f"also, train error is {100 - tr_score * 100:.2f}%")\n',
                "    t_fit, score = te - ts, 1 - score\n",
                "    return t_fit, score\n",
                "\n",
                "\n",
                "def run_sklearn(Xtr, Ytr, Xts, Yts, lambda_reg):\n",
                '    print("SKLearn\'s performance : ")\n',
                "    C = 1 / (2 * Xtr.shape[0] * lambda_reg)\n",
                '    model = svm.LinearSVC(loss="hinge", C=C)\n',
                "    ts = time.perf_counter()\n",
                "    model.fit(Xtr, Ytr)\n",
                "    te = time.perf_counter()\n",
                "    score = model.score(Xts, Yts)\n",
                '    print(f"in {(te - ts):.2f}s, C-err is {100 - score * 100:.2f}%")\n',
                "    t_fit, score = te - ts, 1 - score\n",
                "    return t_fit, score\n",
                "\n",
                "\n",
                "def run_pegasos(Xtr, Ytr, Xts, Yts, nb_iterations, lambda_reg):\n",
                '    print("Pegasos\' performance : ")\n',
                "    C = 1 / (2 * Xtr.shape[0] * lambda_reg)\n",
                "    model = PegasosSVMClassifier(iterations=nb_iterations, lambda_reg=lambda_reg)\n",
                "    ts = time.perf_counter()\n",
                "    model.fit(Xtr, Ytr)\n",
                "    te = time.perf_counter()\n",
                "    score = model.score(Xts, Yts)\n",
                '    print(f"in {(te - ts):.2f}s, C-err is {100 - score * 100:.2f}%")\n',
                "    tr_score = model.score(Xtr, Ytr)\n",
                '    print(f"also, train error is {100 - tr_score * 100:.2f}%")\n',
                "    t_fit, score = te - ts, 1 - score\n",
                "    return t_fit, score",
            ],
        },
        {"cell_type": "markdown", "metadata": {}, "source": ["#### Benchmarking"]},
        {"cell_type": "markdown", "metadata": {}, "source": ["##### a9a"]},
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Snacks' performance : \n",
                        "in 0.38s, C-err is 15.06%\n",
                        "also, train error is 14.74%\n",
                        "SKLearn's performance : \n",
                    ],
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/sofiane/anaconda3/envs/snacks/lib/python3.10/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
                        "  warnings.warn(\n",
                    ],
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "in 7.48s, C-err is 15.16%\n",
                        "Pegasos' performance : \n",
                        "in 1.56s, C-err is 16.56%\n",
                        "also, train error is 15.50%\n",
                    ],
                },
                {
                    "data": {
                        "text/plain": ["(1.560884952545166, 0.16556336586364562)"]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result",
                },
            ],
            "source": [
                'Xtr, Ytr, Xts, Yts = prepare_data("a9a", 1400, 1e-1, False)\n',
                "run_snacks(Xtr, Ytr, Xts, Yts, 45000, 1e-5, 1.0)\n",
                "run_sklearn(Xtr, Ytr, Xts, Yts, 1e-5)\n",
                "run_pegasos(Xtr, Ytr, Xts, Yts, 45000 * 3, 1e-5)",
            ],
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Snacks' performance : \n",
                "in 0.87s, C-err is 15.14%\n",
                "SKLearn's performance : ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
                "in 10.01s, C-err is 15.25%\n",
                "Pegasos' performance : \n",
                "in 3.15s, C-err is 17.18%\n",
                "ThunderSVM's performance : \n",
                "in 4.19s, C-err is 15.40%",
            ],
        },
        {"cell_type": "markdown", "metadata": {}, "source": ["##### SUSY"]},
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                'Xtr, Ytr, Xts, Yts = prepare_data("SUSY", 1050, (1 / (2 * 4 * 4)), True)'
            ],
        },
        {"cell_type": "markdown", "metadata": {}, "source": []},
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "run_snacks(Xtr, Ytr, Xts, Yts, 35000, 3e-6, 0.5)\n",
                "# run_sklearn(Xtr, Ytr, Xts, Yts, 1e-5)\n",
                "run_pegasos(Xtr, Ytr, Xts, Yts, 8000000 * 3, 3e-6)",
            ],
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Snacks' performance : \n",
                "in 2.48s, C-err is 20.26%\n",
                "ThunderSVM's performance : \n",
                "in 1995.73s, C-err is 20.06%\n",
            ],
        },
    ],
    "metadata": {
        "interpreter": {
            "hash": "d4506dcfe8a1cb1985505f6df0f9ad3eb1b024c0303e0c7385d172e3774bf3d5"
        },
        "kernelspec": {
            "display_name": "Python 3.10.0",
            "language": "python",
            "name": "python3",
        },
        "language_info": {
            "codemirror_mode": {"name": "ipython", "version": 3},
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0",
        },
        "orig_nbformat": 4,
    },
    "nbformat": 4,
    "nbformat_minor": 2,
}
